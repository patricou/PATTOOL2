# Rapport d'Audit des Memory Leaks - Backend PatTool

**Date:** 2025-01-27  
**Version:** 1.0  
**Statut:** Analyse compl√®te - Aucune modification effectu√©e

---

## R√©sum√© Ex√©cutif

Cette analyse a identifi√© **8 probl√®mes potentiels de memory leaks** dans le backend, class√©s par niveau de criticit√©. Certains probl√®mes ont d√©j√† √©t√© partiellement corrig√©s (notamment dans `EvenementRestController`), mais d'autres n√©cessitent une attention.

### Probl√®mes Identifi√©s

- **Critiques (3):** N√©cessitent une correction imm√©diate
- **Mod√©r√©s (3):** Devraient √™tre corrig√©s prochainement
- **Faibles (2):** √Ä surveiller mais moins urgents

---

## 1. Probl√®mes Critiques

### 1.1 DiscussionConnectionService - Map de Connexions Non Born√©e

**Fichier:** `com.pat.service.DiscussionConnectionService.java`  
**Ligne:** 37  
**Criticit√©:** üî¥ CRITIQUE

#### Probl√®me

La map `activeConnections` (ConcurrentHashMap) stocke toutes les connexions WebSocket actives sans limite de taille. Si des connexions ne sont pas correctement nettoy√©es (par exemple, en cas de d√©connexion brutale), cette map peut grandir ind√©finiment.

```java
private final Map<String, ConnectionInfo> activeConnections = new ConcurrentHashMap<>();
```

#### Impact

- **M√©moire:** Chaque connexion stocke un objet `ConnectionInfo` avec sessionId, userName, ipAddress, domain, location, connectedAt, discussionId
- **Sc√©nario:** Si 1000 connexions "fant√¥mes" restent dans la map, cela repr√©sente environ 1-2 MB de m√©moire
- **Risque:** En cas de d√©connexions non d√©tect√©es, la map peut grandir jusqu'√† plusieurs milliers d'entr√©es

#### Recommandations

1. **Ajouter une limite de taille** avec nettoyage automatique des entr√©es les plus anciennes
2. **Impl√©menter un nettoyage p√©riodique** des connexions expir√©es (par exemple, toutes les 5 minutes)
3. **Ajouter un m√©canisme de heartbeat** pour d√©tecter les connexions mortes

#### Code Sugg√©r√©

```java
// Limite maximale de connexions
private static final int MAX_CONNECTIONS = 1000;

// Nettoyage p√©riodique des connexions expir√©es
@Scheduled(fixedRate = 300000) // Toutes les 5 minutes
public void cleanupExpiredConnections() {
    long now = System.currentTimeMillis();
    long maxAge = 30 * 60 * 1000; // 30 minutes
    
    activeConnections.entrySet().removeIf(entry -> {
        ConnectionInfo info = entry.getValue();
        long age = now - info.connectedAt.toEpochMilli();
        return age > maxAge;
    });
    
    // Si toujours trop de connexions, supprimer les plus anciennes
    if (activeConnections.size() > MAX_CONNECTIONS) {
        List<Map.Entry<String, ConnectionInfo>> sorted = new ArrayList<>(activeConnections.entrySet());
        sorted.sort(Comparator.comparing(e -> e.getValue().connectedAt));
        
        int toRemove = activeConnections.size() - MAX_CONNECTIONS;
        for (int i = 0; i < toRemove; i++) {
            activeConnections.remove(sorted.get(i).getKey());
        }
    }
}
```

---

### 1.2 FileRestController - Upload Logs Sans Nettoyage Automatique

**Fichier:** `com.pat.controller.FileRestController.java`  
**Lignes:** 82-147  
**Criticit√©:** üî¥ CRITIQUE

#### Probl√®me

La map `uploadLogs` stocke les logs d'upload par sessionId. Bien qu'il y ait une limite de taille (MAX_UPLOAD_SESSIONS = 100), le nettoyage n'est effectu√© que lors de l'ajout de nouveaux logs. Si aucune nouvelle session n'est cr√©√©e, les anciennes sessions peuvent rester ind√©finiment.

```java
private final Map<String, List<String>> uploadLogs = new ConcurrentHashMap<>();
private static final int MAX_UPLOAD_SESSIONS = 100;
```

#### Impact

- **M√©moire:** Chaque session stocke une liste de messages de log
- **Sc√©nario:** Si 100 sessions avec 50 messages chacune restent en m√©moire, cela repr√©sente environ 500 KB - 1 MB
- **Risque:** Les sessions peuvent s'accumuler si le nettoyage manuel (apr√®s 5 secondes) √©choue

#### Recommandations

1. **Ajouter un nettoyage p√©riodique** des logs expir√©s (par exemple, toutes les minutes)
2. **Utiliser un m√©canisme de TTL** pour chaque session
3. **Am√©liorer le nettoyage automatique** apr√®s 5 secondes pour s'assurer qu'il fonctionne toujours

#### Code Sugg√©r√©

```java
// Ajouter un Scheduled task pour nettoyage p√©riodique
@Scheduled(fixedRate = 60000) // Toutes les minutes
public void cleanupExpiredUploadLogs() {
    long now = System.currentTimeMillis();
    long maxAge = 60000; // 1 minute
    
    // Supposer qu'on stocke aussi un timestamp avec chaque session
    // Si ce n'est pas le cas, nettoyer les plus anciennes
    if (uploadLogs.size() > MAX_UPLOAD_SESSIONS) {
        // Supprimer les sessions les plus anciennes
        int toRemove = uploadLogs.size() - MAX_UPLOAD_SESSIONS;
        Iterator<String> iterator = uploadLogs.keySet().iterator();
        for (int i = 0; i < toRemove && iterator.hasNext(); i++) {
            iterator.next();
            iterator.remove();
        }
    }
}
```

---

### 1.3 VideoCompressionService - Process FFmpeg Non Nettoy√© en Cas d'Erreur

**Fichier:** `com.pat.service.VideoCompressionService.java`  
**Lignes:** 121-175  
**Criticit√©:** üî¥ CRITIQUE

#### Probl√®me

Le processus FFmpeg est cr√©√© mais peut ne pas √™tre correctement nettoy√© en cas d'exception ou de timeout. Bien que `destroyForcibly()` soit appel√© en cas de timeout, il n'y a pas de garantie que les ressources syst√®me soient lib√©r√©es.

```java
Process process = processBuilder.start();
// ... traitement ...
if (!finished) {
    process.destroyForcibly();
    // Mais les ressources peuvent ne pas √™tre imm√©diatement lib√©r√©es
}
```

#### Impact

- **Ressources syst√®me:** Chaque processus FFmpeg consomme de la m√©moire syst√®me et des descripteurs de fichiers
- **Sc√©nario:** Si plusieurs compressions √©chouent simultan√©ment, les processus peuvent s'accumuler
- **Risque:** En cas de charge √©lev√©e, cela peut √©puiser les ressources syst√®me

#### Recommandations

1. **Utiliser try-with-resources** ou un m√©canisme de nettoyage garanti
2. **Ajouter un timeout plus court** et un nettoyage forc√©
3. **Limiter le nombre de compressions simultan√©es** avec un Semaphore (comme pour ImageCompressionService)

#### Code Sugg√©r√©

```java
// Ajouter un Semaphore pour limiter les compressions simultan√©es
private final Semaphore compressionSemaphore = new Semaphore(2); // Max 2 compressions simultan√©es

public CompressionResult compressVideo(...) {
    boolean permitAcquired = false;
    Process process = null;
    try {
        compressionSemaphore.acquire();
        permitAcquired = true;
        
        process = processBuilder.start();
        // ... traitement ...
        
    } finally {
        if (process != null) {
            if (process.isAlive()) {
                process.destroyForcibly();
                try {
                    process.waitFor(5, TimeUnit.SECONDS);
                } catch (InterruptedException e) {
                    Thread.currentThread().interrupt();
                }
            }
        }
        if (permitAcquired) {
            compressionSemaphore.release();
        }
    }
}
```

---

## 2. Probl√®mes Mod√©r√©s

### 2.1 ImageCompressionService - Cache Peut Grandir Excessivement

**Fichier:** `com.pat.service.ImageCompressionService.java`  
**Lignes:** 48-50, 608-661  
**Criticit√©:** üü° MOD√âR√â

#### Probl√®me

Le cache de compression d'images a des limites (maxEntries, maxSizeBytes) et un m√©canisme de nettoyage, mais en cas de charge √©lev√©e, le cache peut temporairement d√©passer ces limites avant le nettoyage. De plus, le nettoyage agressif n'est d√©clench√© que lorsque la m√©moire est critique (‚â•85%).

#### Impact

- **M√©moire:** Le cache peut stocker jusqu'√† 200 MB (configurable) d'images compress√©es
- **Sc√©nario:** Si le nettoyage ne se d√©clenche pas assez rapidement, le cache peut consommer plus de m√©moire que pr√©vu
- **Risque:** En cas de slideshow avec beaucoup d'images, le cache peut grandir rapidement

#### Recommandations

1. **Am√©liorer le nettoyage proactif** - d√©clencher le nettoyage avant d'atteindre les limites
2. **Ajouter un nettoyage p√©riodique** en plus du nettoyage √† l'ajout
3. **R√©duire la taille du cache** si la m√©moire est limit√©e

#### Code Sugg√©r√©

```java
// Ajouter un nettoyage p√©riodique
@Scheduled(fixedRate = 300000) // Toutes les 5 minutes
public void cleanupCachePeriodically() {
    long now = System.currentTimeMillis();
    cleanupExpiredEntries(now);
    enforceCacheLimit();
}
```

---

### 2.2 ChatService - Historique de Chat Sans Limite de Taille

**Fichier:** `com.pat.service.ChatService.java`  
**Lignes:** 95-127  
**Criticit√©:** üü° MOD√âR√â

#### Probl√®me

La m√©thode `buildContext()` cr√©e plusieurs `StringBuilder` et listes qui peuvent grandir si l'historique de chat est volumineux. Bien qu'il y ait une limite sur le nombre d'enregistrements charg√©s (maxHistoryRecords), la construction du contexte peut cr√©er des objets temporaires volumineux.

```java
StringBuilder contextBuilder = new StringBuilder();
StringBuilder contextBuilder2 = new StringBuilder();
List<ChatRequest> chatHistory2 = new ArrayList<ChatRequest>();
```

#### Impact

- **M√©moire:** Les StringBuilder peuvent grandir jusqu'√† maxContextSize (10000 caract√®res par d√©faut)
- **Sc√©nario:** Si plusieurs requ√™tes de chat sont trait√©es simultan√©ment, la m√©moire temporaire peut s'accumuler
- **Risque:** En cas de contexte tr√®s long, les StringBuilder peuvent consommer plus de m√©moire que n√©cessaire

#### Recommandations

1. **Limiter la taille des StringBuilder** avec une capacit√© initiale
2. **R√©utiliser les objets** si possible
3. **Nettoyer explicitement** les r√©f√©rences apr√®s utilisation

#### Code Sugg√©r√©

```java
// Limiter la capacit√© initiale des StringBuilder
StringBuilder contextBuilder = new StringBuilder(maxContextSize);
StringBuilder contextBuilder2 = new StringBuilder(maxContextSize);

// Nettoyer apr√®s utilisation
contextBuilder.setLength(0);
contextBuilder2.setLength(0);
chatHistory2.clear();
```

---

### 2.3 FileRestController - InputStream Non Ferm√© dans Certains Cas

**Fichier:** `com.pat.controller.FileRestController.java`  
**Lignes:** 426, 778  
**Criticit√©:** üü° MOD√âR√â

#### Probl√®me

L'`InputStream` retourn√© par `gridFsResource.getInputStream()` dans `getFile()` est encapsul√© dans un `InputStreamResource` qui devrait √™tre g√©r√© par Spring, mais il n'y a pas de garantie explicite de fermeture. De m√™me, l'`InputStream` utilis√© dans `postFile()` pour `gridFsTemplate.store()` peut ne pas √™tre ferm√© en cas d'exception.

#### Impact

- **Ressources:** Les InputStream non ferm√©s peuvent garder des descripteurs de fichiers ouverts
- **Sc√©nario:** Si de nombreux fichiers sont servis simultan√©ment, les descripteurs peuvent s'√©puiser
- **Risque:** En cas de charge √©lev√©e, cela peut causer des erreurs "too many open files"

#### Recommandations

1. **Utiliser try-with-resources** pour garantir la fermeture
2. **V√©rifier que Spring ferme correctement** les InputStreamResource
3. **Ajouter un m√©canisme de nettoyage** pour les InputStream en cas d'erreur

#### Code Sugg√©r√©

```java
// Pour getFile()
try (InputStream inputStream = gridFsResource.getInputStream()) {
    return ResponseEntity.ok()
        .headers(headers)
        .body(new InputStreamResource(inputStream));
}

// Pour postFile()
try (InputStream inputStream = ...) {
    String fieldId = gridFsTemplate.store(inputStream, ...).toString();
    // ...
} // InputStream ferm√© automatiquement
```

---

## 3. Probl√®mes Faibles

### 3.1 CachePersistenceService - Fichiers Temporaires Non Nettoy√©s en Cas d'Erreur

**Fichier:** `com.pat.service.CachePersistenceService.java`  
**Lignes:** 75-102, 131-170  
**Criticit√©:** üü¢ FAIBLE

#### Probl√®me

Les `ObjectInputStream` et `ObjectOutputStream` sont utilis√©s avec try-with-resources, ce qui est correct. Cependant, si une exception survient pendant l'√©criture, le fichier de cache peut √™tre corrompu et rester sur le disque.

#### Impact

- **Disque:** Les fichiers corrompus peuvent s'accumuler
- **Sc√©nario:** Si plusieurs sauvegardes √©chouent, les fichiers peuvent s'accumuler
- **Risque:** Faible, mais peut consommer de l'espace disque

#### Recommandations

1. **Ajouter un nettoyage des fichiers corrompus** lors du chargement
2. **Valider l'int√©grit√©** du fichier avant de le charger
3. **Ajouter un m√©canisme de backup** avant d'√©craser le fichier existant

---

### 3.2 EvenementRestController - SseEmitter Non Nettoy√© en Cas d'Erreur

**Fichier:** `com.pat.controller.EvenementRestController.java`  
**Lignes:** 137-464  
**Criticit√©:** üü¢ FAIBLE

#### Probl√®me

Les `SseEmitter` sont cr√©√©s et g√©r√©s avec des callbacks `onCompletion`, `onTimeout`, et `onError`, ce qui est correct. Cependant, en cas d'exception non g√©r√©e dans le `CompletableFuture`, l'emitter peut ne pas √™tre correctement nettoy√©.

#### Impact

- **M√©moire:** Les SseEmitter non nettoy√©s peuvent garder des r√©f√©rences aux objets
- **Sc√©nario:** Si plusieurs streams √©chouent simultan√©ment, les emitters peuvent s'accumuler
- **Risque:** Faible, car les callbacks devraient g√©rer la plupart des cas

#### Recommandations

1. **Ajouter un nettoyage explicite** dans le bloc finally du CompletableFuture
2. **V√©rifier que tous les chemins d'exception** appellent `emitter.complete()` ou `emitter.completeWithError()`
3. **Ajouter un timeout** plus court pour forcer le nettoyage

---

## 4. Probl√®mes D√©j√† Corrig√©s

### 4.1 EvenementRestController - ExecutorService

**Fichier:** `com.pat.controller.EvenementRestController.java`  
**Lignes:** 112-118, 1597-1618  
**Statut:** ‚úÖ CORRIG√â

Le `ExecutorService` utilise maintenant un `ThreadPoolExecutor` born√© avec un `@PreDestroy` pour le nettoyage. C'est correct.

### 4.2 EvenementRestController - Accumulation d'√âv√©nements Null-Dated

**Fichier:** `com.pat.controller.EvenementRestController.java`  
**Lignes:** 233, 262-284  
**Statut:** ‚úÖ CORRIG√â

La liste `nullDateEvents` est limit√©e √† 1000 √©l√©ments avec un envoi imm√©diat si la limite est atteinte. C'est correct.

---

## 5. Recommandations G√©n√©rales

### 5.1 Monitoring et Alertes

1. **Ajouter des m√©triques** pour surveiller:
   - Taille des maps/caches en m√©moire
   - Nombre de processus FFmpeg actifs
   - Nombre de connexions WebSocket actives
   - Nombre de descripteurs de fichiers ouverts

2. **Configurer des alertes** lorsque:
   - La m√©moire d√©passe 85%
   - Le nombre de connexions d√©passe un seuil
   - Le cache d√©passe 80% de sa taille maximale

### 5.2 Tests de Charge

1. **Effectuer des tests de charge** pour identifier les memory leaks sous charge
2. **Utiliser des outils de profilage** (VisualVM, JProfiler, Eclipse MAT) pour analyser les heap dumps
3. **Surveiller la m√©moire** sur une p√©riode prolong√©e (plusieurs heures/jours)

### 5.3 Configuration

1. **Ajuster les limites** selon la capacit√© du serveur:
   - `MAX_CONNECTIONS` dans DiscussionConnectionService
   - `MAX_UPLOAD_SESSIONS` dans FileRestController
   - `cacheMaxSizeMB` dans ImageCompressionService

2. **Configurer les timeouts** appropri√©s:
   - Timeout pour les processus FFmpeg
   - Timeout pour les connexions WebSocket
   - TTL pour les caches

---

## 6. Plan d'Action Recommand√©

### Priorit√© 1 (Imm√©diat)
1. ‚úÖ Corriger DiscussionConnectionService - ajouter nettoyage p√©riodique
2. ‚úÖ Corriger FileRestController - am√©liorer nettoyage des upload logs
3. ‚úÖ Corriger VideoCompressionService - ajouter Semaphore et nettoyage garanti

### Priorit√© 2 (Court terme)
4. Am√©liorer ImageCompressionService - nettoyage p√©riodique
5. Optimiser ChatService - limiter taille des StringBuilder
6. V√©rifier fermeture des InputStream dans FileRestController

### Priorit√© 3 (Moyen terme)
7. Am√©liorer CachePersistenceService - nettoyage fichiers corrompus
8. V√©rifier nettoyage SseEmitter dans EvenementRestController

---

## 7. Conclusion

Le backend pr√©sente plusieurs probl√®mes potentiels de memory leaks, mais la plupart sont g√©rables avec des corrections cibl√©es. Les probl√®mes critiques doivent √™tre corrig√©s en priorit√©, notamment:

1. **DiscussionConnectionService** - risque de croissance illimit√©e de la map de connexions
2. **FileRestController** - logs d'upload qui peuvent s'accumuler
3. **VideoCompressionService** - processus FFmpeg non nettoy√©s

Les probl√®mes mod√©r√©s et faibles peuvent √™tre trait√©s progressivement, mais ne repr√©sentent pas un risque imm√©diat pour la stabilit√© de l'application.

**Note:** Cette analyse est bas√©e sur une revue statique du code. Des tests de charge et un profilage en conditions r√©elles sont recommand√©s pour confirmer et quantifier les probl√®mes identifi√©s.

---

**Fin du Rapport**

